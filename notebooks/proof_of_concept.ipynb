{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of concept\n",
    "Small notebook illustrating how DHFRs change their appearance according to the type of editing executed on the spliced area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries importing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from isplutils.network import DnCNN\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (7, 7)\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_dir = '../data/poc' # directory containing the sample images used in the paper\n",
    "gpu = 3 # GPU ID to use\n",
    "model_dir = '../weights/'\n",
    "sample_paths = glob.glob(os.path.join(data_dir, '*.tiff'))\n",
    "sample_paths = {os.path.basename(path).split('.')[0]: path for path in sample_paths}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f'{gpu}'  # set the GPU device\n",
    "\n",
    "print('tf    version:', tf.__version__)\n",
    "print('keras version:', keras.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "configSess = tf.ConfigProto()\n",
    "# Allowing the GPU memory to grow avoid preallocating all the GPU memory\n",
    "configSess.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=configSess))\n",
    "\n",
    "# define the network and load weights\n",
    "model = DnCNN(model_path=model_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the images and extract the DHFRs\n",
    "Test images are VV-polarization GRD Sentinel-1 samples, that have been normalized using a simple multiplicative scaling (normalization strategies of the original paper) and converted to 8-bit to ease of use.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import sklearn\n",
    "\n",
    "fsize = 20  # fontsize\n",
    "\n",
    "sorted_editing = ['AverageBlur', 'MedianBlur', 'RotationResize', 'AdditiveWhiteGaussianNoise', 'AdditiveLaplacianNoise', 'SpeckleNoise']\n",
    "for editing in sorted_editing:\n",
    "\n",
    "    # --- Load the sample path using rasterio\n",
    "    path = sample_paths[editing]\n",
    "    with rasterio.open(path, 'r') as src:\n",
    "        img = np.squeeze(src.read())\n",
    "\n",
    "    # --- Extract the DHFR\n",
    "    img_float = img.astype(np.float32)\n",
    "    img_float = (img_float-img_float.min())/(img_float.max()-img_float.min()) # simple min-max scaling between 0-1\n",
    "    img_float = img_float[np.newaxis, :, :, np.newaxis] # add batch dimension\n",
    "    dhfr = model.predict(img_float)\n",
    "\n",
    "    # --- Plot images and DHFRs, together with the ROC curve to illustrate how the appearance of the DHFR influences the AUC value\n",
    "\n",
    "    # Load the reference mask\n",
    "    mask = cv2.imread(os.path.join(data_dir, 'mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_RGBA2GRAY)\n",
    "\n",
    "    # Compute the ROC curve ad AUC\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(mask.ravel(), dhfr.ravel(), pos_label=255)\n",
    "    auc = np.trapz(tpr, fpr)\n",
    "\n",
    "    # Normalize the DHFR for visualization\n",
    "    dhfr = np.squeeze(((dhfr-dhfr.min())/(dhfr.max()-dhfr.min())))\n",
    "    dhfr = (dhfr*255).astype(np.uint8)\n",
    "\n",
    "    # Prepare the plot\n",
    "    plt.figure(figsize=(25,23))\n",
    "    plt.suptitle(f'DHFR for {editing} editing', y=0.65, fontsize=fsize)\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(img, cmap='gray', clim=[0, 255])\n",
    "    plt.title('Input image', fontsize=fsize-5)\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(dhfr, cmap='gray')\n",
    "    plt.title('DHFR', fontsize=fsize-5)\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title('Ground truth', fontsize=fsize-5)\n",
    "    plt.subplot(144)\n",
    "    plt.plot(fpr, tpr, label=f\"AUC score {auc:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.xlabel('FPR', fontsize=fsize-7)\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.ylabel('TPR', fontsize=fsize-7)\n",
    "    plt.grid()\n",
    "    plt.axis(\"image\")\n",
    "    plt.legend(fontsize=fsize-7)\n",
    "    plt.title('ROC curve', fontsize=fsize-5)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's highlight and zoom-in in the tampered areas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sorted_editing = ['AverageBlur', 'MedianBlur', 'RotationResize', 'AdditiveWhiteGaussianNoise', 'AdditiveLaplacianNoise', 'SpeckleNoise']\n",
    "for editing in sorted_editing:\n",
    "\n",
    "    # --- Load the sample path using rasterio\n",
    "    path = sample_paths[editing]\n",
    "    with rasterio.open(path, 'r') as src:\n",
    "        img = np.squeeze(src.read())\n",
    "\n",
    "    # --- Extract the DHFR\n",
    "    img_float = img.astype(np.float32)\n",
    "    img_float = (img_float-img_float.min())/(img_float.max()-img_float.min()) # simple min-max scaling between 0-1\n",
    "    img_float = img_float[np.newaxis, :, :, np.newaxis] # add batch dimension\n",
    "    dhfr = model.predict(img_float)\n",
    "\n",
    "    # --- Plot images and DHFRs, together with the ROC curve to illustrate how the appearance of the DHFR influences the AUC value\n",
    "\n",
    "    # Load the reference mask\n",
    "    mask = cv2.imread(os.path.join(data_dir, 'mask.png'), cv2.IMREAD_UNCHANGED)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_RGBA2GRAY)\n",
    "\n",
    "    # Normalize the DHFR for visualization\n",
    "    dhfr = np.squeeze(((dhfr-dhfr.min())/(dhfr.max()-dhfr.min())))\n",
    "    dhfr = (dhfr*255).astype(np.uint8)\n",
    "\n",
    "    # Find the mask countours\n",
    "    mask = mask > 200\n",
    "    mask = (mask.astype(np.uint8))*255\n",
    "    edges = cv2.Canny(mask, 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    # Prepare the plot\n",
    "    plt.figure(figsize=(25,23))\n",
    "    plt.suptitle(f'DHFR for {editing} editing', y=0.65, fontsize=fsize)\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img, cmap='gray', clim=[0, 255])\n",
    "    plt.plot(contours[-1][:, :, 0].flatten(), contours[-1][:, :, 1].flatten(), color='red')\n",
    "    plt.title('Input image', fontsize=fsize-5)\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(dhfr, cmap='gray')\n",
    "    plt.title('DHFR', fontsize=fsize-5)\n",
    "    plt.plot(contours[-1][:, :, 0].flatten(), contours[-1][:, :, 1].flatten(), color='red')\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.title('Ground truth', fontsize=fsize-5)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('test_imgs/nice_images_quickshift/df_nice_looking_images.pkl')\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "    # Load the sample\n",
    "    sample = cv2.imread(os.path.join('test_imgs/nice_images_quickshift', r['forged_image']), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # Plot the image with contour\n",
    "    plt.imshow(sample, cmap='gray')\n",
    "    plt.plot(contours[-1][:, :, 0].flatten(), contours[-1][:, :, 1].flatten(), color='red')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join('test_imgs/nice_images_quickshift', f\"{r['forged_image'].split('.png')[0]}_tamp.png\"),\n",
    "                bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's also save the close-up"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('test_imgs/nice_images_quickshift/df_nice_looking_images.pkl')\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "    # Load the sample\n",
    "    sample = cv2.imread(os.path.join('test_imgs/nice_images_quickshift', r['forged_image']), cv2.IMREAD_UNCHANGED)\n",
    "    print(r['forged_image'])\n",
    "    # Plot the image with contour\n",
    "    edges = cv2.Canny(mask[450:750, 250:550], 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    plt.imshow(sample[450:750, 250:550], cmap='gray')\n",
    "    plt.plot(contours[-1][:, :, 0].flatten(), contours[-1][:, :, 1].flatten(), color='red')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join('test_imgs/nice_images_quickshift', f\"{r['forged_image'].split('.png')[0]}_tamp_closeup.png\"),\n",
    "                bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And also repeat for the fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for i, r in df.iterrows():\n",
    "    # Load the sample\n",
    "    sample = cv2.imread(os.path.join('test_imgs/nice_images_quickshift', r['forged_noiseprint']), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # Plot the image with contour\n",
    "    edges = cv2.Canny(mask, 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    plt.imshow(sample, cmap='gray', clim=[0, 255])\n",
    "    plt.plot(contours[-1][:, :, 0].flatten(), contours[-1][:, :, 1].flatten(), color='red')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join('test_imgs/nice_images_quickshift', f\"{r['forged_noiseprint'].split('.png')[0]}_tamp.png\"),\n",
    "                bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for i, r in df.iterrows():\n",
    "    # Load the sample\n",
    "    sample = cv2.imread(os.path.join('test_imgs/nice_images_quickshift', r['forged_noiseprint']), cv2.IMREAD_UNCHANGED)\n",
    "    sample = (sample-sample.min())/(sample.max()-sample.min())\n",
    "    print(f'{r[\"forged_image\"]}, {sample.min()}, {sample.max()}')\n",
    "    # Plot the image with contour\n",
    "    edges = cv2.Canny(mask[450:750, 250:550], 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    plt.imshow(sample[450:750, 250:550], cmap='gray', clim=[sample[450:750, 250:550].min(), sample[450:750, 250:550].max()])\n",
    "    plt.plot(contours[-1][:, :, 0].flatten(), contours[-1][:, :, 1].flatten(), color='red')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join('test_imgs/nice_images_quickshift', f\"{r['forged_noiseprint'].split('.png')[0]}_tamp_closeup.png\"),\n",
    "                bbox_inches='tight')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
